{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the necessary libraries are imported, the following actions are performed:\n",
    "\n",
    "- Load Labelled Data:<br>\n",
    "Here we have the PDF names (or Data IDs) and we also have manually marked which pages on these PDFs are maps. First, we create the dataframe of the features by extracting the features of each page on these PDFs using the function \"extract_features\". Then by using the marked values of each page being map or not we create the dataframe for the dependent variable. The variable \"dataID_pageNo\" is onnly used to identify a certain page. \n",
    "- Train Test Split: <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import extract_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Labeled Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "path_pdf = \"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\RF Training Set\\\\\"\n",
    "\n",
    "DataIDHand = [268712,  486221, 500633, \n",
    "               555093, 684494, \n",
    "              895015, 2392922, 2445549, 2758927,\n",
    "              2813701,  \n",
    "              2967854, 2968069,  \n",
    "              3891802,\n",
    "              4036098]\n",
    "Pages = [[3,4,5,8,9,10,14,15,24,25,26], range(1,5),  [5,9], \n",
    "          [6,9,33,34], [12,13,14],\n",
    "         range(1,11), [1], range(1,4),  [9],\n",
    "         [40, 92, 95, 143, 170, 180, 216, 217, 218, 219],\n",
    "         [3,4],range(1,13),  \n",
    "         [33, 34, 35, 89, 90, 91, 92, 93, 100, 146, 147, 148, 149, 153, 154, 159, 160, 161, 162, 165, 166, 169, 170, 173, 174, 177, 178, 181, 182, 184, 185, 188, 189], \n",
    "          []]\n",
    "\n",
    "print(len(DataIDHand))\n",
    "print(len(Pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fetching featuresfor the pages of the PDF Files\n",
    "# X_df, dataIDs, error_files = extract_features(DataIDHand, path_pdf) \n",
    "# #Features\n",
    "# #dataIDs\n",
    "# #error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_test_train.csv\")\n",
    "# dataIDs.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs.csv\")\n",
    "# print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_test_train.csv\", index_col = 0)\n",
    "dataIDs = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs.csv\", index_col = 0)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_features = X_df.copy()\n",
    "X_df_features.drop(columns=['dataID_pageNo'], inplace=True)\n",
    "X_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Y_values(dataIDs, Pages):\n",
    "    Y_class = []\n",
    "    dataID_pageNo = []\n",
    "    j = 0\n",
    "    for index, row in dataIDs.iterrows():\n",
    "        #print(row['DataIDs'])\n",
    "        #print(row['Page_no'])\n",
    "        for i in range(1,row['Page_no']+1):\n",
    "            if i in Pages[j]:\n",
    "                Y_class.append(1)\n",
    "            else:\n",
    "                Y_class.append(0)\n",
    "            dataID_pageNo.append(str(row['DataIDs']) + \"_\" +str(i))\n",
    "        j = j+1\n",
    "    \n",
    "    Y_df = pd.DataFrame({'dataID_pageNo' : dataID_pageNo, \n",
    "                         'Y_class' : Y_class})\n",
    "    Y_dfclass = pd.DataFrame({'Y_class' : Y_class})\n",
    "    \n",
    "    return Y_df, Y_dfclass\n",
    "    \n",
    "                \n",
    "Y_df, Y_dfclass = get_Y_values(dataIDs, Pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_df))\n",
    "print(len(X_df))\n",
    "print(len(Y_dfclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df_features,\n",
    "                                                    Y_dfclass,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Set: \", len(y_train))\n",
    "print(\"Alignment Sheets in Training Set: \", len(y_train[y_train.Y_class > 0]))\n",
    "print()\n",
    "print(\"Test Set: \", len(y_test))\n",
    "print(\"Alignment Sheets in Training Set: \", len(y_test[y_test.Y_class > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(19)\n",
    "\n",
    "classifiers = []\n",
    "name = []\n",
    "# we will create an array of Classifiers and append different classification models to our array.\n",
    "model1 = xgboost.XGBClassifier()\n",
    "classifiers.append(model1)\n",
    "name.append(\"xgboost\")\n",
    "\n",
    "model2 = svm.SVC()\n",
    "classifiers.append(model2)\n",
    "name.append(\"svc\")\n",
    "\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "name.append(\"decisiontree\")\n",
    "\n",
    "model4 = RandomForestClassifier()\n",
    "classifiers.append(model4)\n",
    "name.append(\"rfc\")\n",
    "\n",
    "\n",
    "model5 = RandomForestRegressor(n_estimators=5)\n",
    "classifiers.append(model5)\n",
    "name.append(\"rfr5\")\n",
    "\n",
    "model6 = RandomForestRegressor(n_estimators=25)\n",
    "classifiers.append(model6)\n",
    "name.append(\"rfr25\")\n",
    "\n",
    "model7 = RandomForestRegressor(n_estimators=50)\n",
    "classifiers.append(model7)\n",
    "name.append(\"rfr50\")\n",
    "\n",
    "model8 = RandomForestRegressor(n_estimators=75)\n",
    "classifiers.append(model8)\n",
    "name.append(\"rfr75\")\n",
    "\n",
    "model9 = RandomForestRegressor(n_estimators=100)\n",
    "classifiers.append(model9)\n",
    "name.append(\"rfr100\")\n",
    "\n",
    "\n",
    "model10 = XGBRegressor(n_estimators=5)\n",
    "classifiers.append(model10)\n",
    "name.append(\"xgbr5\")\n",
    "\n",
    "model11 = XGBRegressor(n_estimators=25)\n",
    "classifiers.append(model11)\n",
    "name.append(\"xgbr25\")\n",
    "\n",
    "model12 = XGBRegressor(n_estimators=50)\n",
    "classifiers.append(model12)\n",
    "name.append(\"xgbr50\")\n",
    "\n",
    "model13 = XGBRegressor(n_estimators=75)\n",
    "classifiers.append(model13)\n",
    "name.append(\"xgbr75\")\n",
    "\n",
    "model14 = XGBRegressor(n_estimators=100)\n",
    "classifiers.append(model14)\n",
    "name.append(\"xgbr100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "test_accuracy = []\n",
    "for clf in classifiers:\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"________________________________________________________\")\n",
    "    #fit our algorithms in our Train dataset \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #get test dataset prediction\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_test)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_test)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    test_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataIDHand = [3410189, 3970828, 2968356]\n",
    "Pages = [[], \n",
    "         [29, 35, 51, 59, 100, 101, 108, 109, 165, 179, 225, 231, 293, 294], \n",
    "         [9,18, 26]]\n",
    "\n",
    "print(len(DataIDHand))\n",
    "print(len(Pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_pdf = \"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\RF Validation Set\\\\\"\n",
    "\n",
    "# # #fetching featuresfor the pages of the PDF Files\n",
    "# X_df_valid, dataIDs_valid, error_files = extract_features(DataIDHand, path_pdf) \n",
    "# # #Features\n",
    "# # #dataIDs\n",
    "# # #error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df_valid.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_valid.csv\")\n",
    "# dataIDs_valid.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs_valid.csv\")\n",
    "# print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_valid = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_valid.csv\", index_col = 0)\n",
    "dataIDs_valid = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs_valid.csv\", index_col = 0)\n",
    "X_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_features_valid = X_df_valid.copy()\n",
    "X_df_features_valid.drop(columns=['dataID_pageNo'], inplace=True)\n",
    "X_df_features_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df_valid, Y_dfclass_valid = get_Y_values(dataIDs_valid, Pages)\n",
    "\n",
    "print(len(Y_df_valid))\n",
    "print(len(X_df_features_valid))\n",
    "print(len(X_df_valid))\n",
    "print(len(Y_dfclass_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "cm_test = []\n",
    "cm_valid = []\n",
    "for clf in classifiers:\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"________________________________________________________\")\n",
    "    #fit our algorithms in our Train dataset \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #get test dataset prediction\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_test)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_test)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    test_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    cm_test.append(cm)\n",
    "    \n",
    "    \n",
    "    print(\"________________Validation Set ___________________________\")\n",
    "    #get validation accuracy\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_df_features_valid)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_df_features_valid)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(Y_dfclass_valid[\"Y_class\"], y_pred)\n",
    "    valid_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(Y_dfclass_valid[\"Y_class\"], y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    cm_valid.append(cm)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = pd.DataFrame({'name': name, \n",
    "                                     'test_accuracy': test_accuracy,\n",
    "                                     'test_cm': cm_test, \n",
    "                                     'valid_accuracy':valid_accuracy,\n",
    "                                     'valid_cm': cm_valid})\n",
    "classification_models[\"product\"] = classification_models[\"test_accuracy\"]*classification_models[\"valid_accuracy\"]\n",
    "\n",
    "classification_models = classification_models.sort_values(by=['product'])\n",
    "classification_models.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "\n",
    "for clf in classifiers:\n",
    "    \n",
    "    if name[i] != \"rfc\":\n",
    "        i = i +1\n",
    "        continue\n",
    "    print(name[i])\n",
    "    clf.fit(X_train, y_train)\n",
    "    filename = \"G:\\\\ESA_downloads\\\\Demo_Alignment_Sheets\\\\alignment_sheet_classifier_rfc.sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    \n",
    "    filename = \"alignment_sheet_classifier_rfr50.sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "#n_estimators - Number of trees in the forest \n",
    "#random_state - Controls both the randomness of the bootstrapping of the samples used when building \n",
    "              # trees (if bootstrap=True) and the sampling of the features to consider when looking \n",
    "              # for the best split at each node (if max_features < n_features)\n",
    "# Ref -> https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "file_name =  \"alignment_sheet_classifier_rfr.sav\"\n",
    "pickle.dump(regressor, open(file_name, 'wb'))\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "#y_pred.shape\n",
    "#y_pred\n",
    "y_predict = []\n",
    "for y in y_pred:\n",
    "    if y > 0.40:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)\n",
    "#y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_importance = regressor.feature_importances_\n",
    "feature = []\n",
    "\n",
    "for col in X_df_features:\n",
    "    feature.append(col)\n",
    "    \n",
    "df_f_importance = pd.DataFrame({'Feature_Name' :  feature, \n",
    "                                'Importance':  f_importance})\n",
    "df_f_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XYRdf_dataset = X_test\n",
    "XYRdf_dataset['Y_test'] = y_test\n",
    "XYRdf_dataset['y_score'] = y_pred\n",
    "XYRdf_dataset['y_predict'] = y_predict\n",
    "#XYRdf_dataset['dataID_pageNo' : dataID_pageNo]\n",
    "len(XYRdf_dataset)\n",
    "XYRdf_dataset.head()\n",
    "\n",
    "\n",
    "XYRdf_dataset.to_csv(path_pdf + \"Results_Training_Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
