{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to find the best porforming classification models. We will be training the models to determine the if any particular page on a PDF is a map (aka alignment sheet) or not. \n",
    "\n",
    "\n",
    "In this code we will Once the necessary libraries are imported, the following actions are performed:\n",
    "\n",
    "- <strong>Load labelled data: </strong>\n",
    "Here we generate the features using \"extract_features\" function.  \n",
    "\n",
    "- <strong>Train test split: </strong>\n",
    "Split the dataset into test and train set. \n",
    "\n",
    "- <strong>Prepare validation set: </strong>\n",
    "Create validation dataframe.\n",
    "\n",
    "- <strong>Implement classification models: </strong>\n",
    "Train various classification models and then get accuracy score and confusion matric for test and validation set.  \n",
    "\n",
    "- <strong>Compare models: </strong>\n",
    "Compare the accuracy score and the confusion matrix and save the best model for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import extract_features\n",
    "\n",
    "path = os.getcwd()\n",
    "path = os.path.abspath('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labeled data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the PDF names (or Data IDs) and we also have manually marked which pages on these PDFs are maps. First, we create the dataframe of the features by extracting the features of each page on these PDFs using the function \"extract_features\". Then by using the marked values of each page being map or not we create the dataframe for the dependent variable. The variable \"dataID_pageNo\" is onnly used to identify a certain page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "path_pdf = path + \"\\\\TrainingSet\\\\\"\n",
    "\n",
    "DataIDHand = [268712,  486221, 500633, \n",
    "               555093, 684494, \n",
    "              895015, 2392922, 2445549, 2758927,\n",
    "              2813701,  \n",
    "              2967854, 2968069,  \n",
    "              3891802,\n",
    "              4036098]\n",
    "Pages = [[3,4,5,8,9,10,14,15,24,25,26], range(1,5),  [5,9], \n",
    "          [6,9,33,34], [12,13,14],\n",
    "         range(1,11), [1], range(1,4),  [9],\n",
    "         [40, 92, 95, 143, 170, 180, 216, 217, 218, 219],\n",
    "         [3,4],range(1,13),  \n",
    "         [33, 34, 35, 89, 90, 91, 92, 93, 100, 146, 147, 148, 149, 153, 154, 159, 160, 161, 162, 165, 166, 169, 170, 173, 174, 177, 178, 181, 182, 184, 185, 188, 189], \n",
    "          []]\n",
    "\n",
    "print(\"Number of PDFs: \", len(DataIDHand), \". Len of Pages array:\" len(Pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Starting: 268712. PDF 1 out of 14\n",
      "File Starting: 486221. PDF 2 out of 14\n",
      "File Starting: 500633. PDF 3 out of 14\n",
      "File Starting: 555093. PDF 4 out of 14\n",
      "File Starting: 684494. PDF 5 out of 14\n",
      "File Starting: 895015. PDF 6 out of 14\n",
      "File Starting: 2392922. PDF 7 out of 14\n",
      "File Starting: 2445549. PDF 8 out of 14\n",
      "File Starting: 2758927. PDF 9 out of 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: invalid page object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Starting: 2813701. PDF 10 out of 14\n",
      "File Starting: 2967854. PDF 11 out of 14\n",
      "File Starting: 2968069. PDF 12 out of 14\n",
      "File Starting: 3891802. PDF 13 out of 14\n",
      "File Starting: 4036098. PDF 14 out of 14\n"
     ]
    }
   ],
   "source": [
    "# # No need to run this code if the features are alredy saved\n",
    "# # Fetching features for each page of the PDF Files and saving them \n",
    "# X_df, dataIDs, error_files = extract_features(DataIDHand, path_pdf) \n",
    "\n",
    "# print(\"\\n Number of Error files\", len(error_files))\n",
    "# X_df.to_csv(path + \"\\\\data\\\\features_test_train.csv\")\n",
    "# dataIDs.to_csv(path + \"\\\\data\\\\dataIDs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1182</td>\n",
       "      <td>1</td>\n",
       "      <td>79376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1747</td>\n",
       "      <td>1</td>\n",
       "      <td>79376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>2</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>857</td>\n",
       "      <td>2</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>775</td>\n",
       "      <td>2</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scale  km_kilometers    m  metres  scale_grp  legend  figure  mapp  \\\n",
       "0      0              0  171       0          0       0       0     0   \n",
       "1      0              0  195       0          0       0       1     0   \n",
       "2      2              1   87       1          1       0       1     0   \n",
       "3      2              1   99       1          1       0       1     0   \n",
       "4      2              1   89       1          1       0       1     0   \n",
       "\n",
       "   alignment_sheet  sheet  figure_grp  north  n  words_in_page  No_of_images  \\\n",
       "0                0      0           0      0  0           1182             1   \n",
       "1                0      0           1      0  0           1747             1   \n",
       "2                0      0           1      0  0            755             2   \n",
       "3                0      0           1      0  0            857             2   \n",
       "4                0      0           1      0  0            775             2   \n",
       "\n",
       "   Area_of_images  \n",
       "0           79376  \n",
       "1           79376  \n",
       "2            3433  \n",
       "3            3433  \n",
       "4            3433  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.read_csv(path + \"\\\\data\\\\features_test_train.csv\", index_col = 0)\n",
    "dataIDs = pd.read_csv(path + \"\\\\data\\\\dataIDs.csv\", index_col = 0)\n",
    "\n",
    "# Keepin only the features (remove index)\n",
    "X_df_features = X_df.copy()\n",
    "X_df_features.drop(columns=['dataID_pageNo'], inplace=True)\n",
    "X_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Y_values(dataIDs, Pages):\n",
    "    Y_class = []\n",
    "    dataID_pageNo = []\n",
    "    j = 0\n",
    "    for index, row in dataIDs.iterrows():\n",
    "        #print(row['DataIDs'])\n",
    "        #print(row['Page_no'])\n",
    "        for i in range(1,row['Page_no']+1):\n",
    "            if i in Pages[j]:\n",
    "                Y_class.append(1)\n",
    "            else:\n",
    "                Y_class.append(0)\n",
    "            dataID_pageNo.append(str(row['DataIDs']) + \"_\" +str(i))\n",
    "        j = j+1\n",
    "    \n",
    "    Y_df = pd.DataFrame({'dataID_pageNo' : dataID_pageNo, \n",
    "                         'Y_class' : Y_class})\n",
    "    Y_dfclass = pd.DataFrame({'Y_class' : Y_class})\n",
    "    \n",
    "    return Y_df, Y_dfclass\n",
    "    \n",
    "                \n",
    "Y_df, Y_dfclass = get_Y_values(dataIDs, Pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "994\n",
      "994\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_df))\n",
    "print(len(X_df))\n",
    "print(len(Y_dfclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the seed value to get the same results when rerunning the code. Then we split the dataset randomly into train set and test set. (train set = 0.75, test set =0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(745, 16)\n",
      "(249, 16)\n",
      "(745, 1)\n",
      "(249, 1)\n"
     ]
    }
   ],
   "source": [
    "random.seed(19)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df_features,\n",
    "                                                    Y_dfclass,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  745\n",
      "Alignment Sheets in Training Set:  67\n",
      "\n",
      "Test Set:  249\n",
      "Alignment Sheets in Training Set:  29\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set: \", len(y_train))\n",
    "print(\"Alignment Sheets in Training Set: \", len(y_train[y_train.Y_class > 0]))\n",
    "print()\n",
    "print(\"Test Set: \", len(y_test))\n",
    "print(\"Alignment Sheets in Training Set: \", len(y_test[y_test.Y_class > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the validation set we make use of new PDFs representing a new real world problem. For validation sets we would except slighly lower level of accuracy. The model which performs better on validation set typically performs better overall. \n",
    "\n",
    "We extract features using 'extract_features' function as earlier. Then we create validation dataframes for features and dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "DataIDHand = [2968356, 3410189, 3970828]\n",
    "Pages = [[9,18, 26], \n",
    "         [], \n",
    "         [29, 35, 51, 59, 100, 101, 108, 109, 165, 179, 225, 231, 293, 294]]\n",
    "\n",
    "print(len(DataIDHand))\n",
    "print(len(Pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Starting: 2968356. PDF 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Starting: 3410189. PDF 2 out of 3\n",
      "File Starting: 3970828. PDF 3 out of 3\n"
     ]
    }
   ],
   "source": [
    "path_pdf = (path + \"\\\\ValidationSet\\\\\")\n",
    "\n",
    "# #fetching featuresfor the pages of the PDF Files\n",
    "X_df_valid, dataIDs_valid, error_files = extract_features(DataIDHand, path_pdf) \n",
    "# #Features\n",
    "# #dataIDs\n",
    "# #error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "X_df_valid.to_csv(path + \"\\\\data\\\\features_valid.csv\")\n",
    "dataIDs_valid.to_csv(path + \"\\\\data\\\\dataIDs_valid.csv\")\n",
    "print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "      <th>dataID_pageNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2968356_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2968356_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2968356_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2968356_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2968356_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scale  km_kilometers    m  metres  scale_grp  legend  figure  mapp  \\\n",
       "0      0              0    0       0          0       0       0     0   \n",
       "1      0              0    0       0          0       0       0     0   \n",
       "2      0              0    0       0          0       0       0     0   \n",
       "3      0              0  280       6          1       0       5     0   \n",
       "4      0              1  216       7          1       0       0     0   \n",
       "\n",
       "   alignment_sheet  sheet  figure_grp  north  n  words_in_page  No_of_images  \\\n",
       "0                0      0           0      0  0            424             0   \n",
       "1                0      0           0      0  0             23             0   \n",
       "2                0      0           0      0  0           2243             0   \n",
       "3                0      0           1      0  0           2336             0   \n",
       "4                0      0           0      1  0           1149             0   \n",
       "\n",
       "   Area_of_images dataID_pageNo  \n",
       "0               0     2968356_1  \n",
       "1               0     2968356_2  \n",
       "2               0     2968356_3  \n",
       "3               0     2968356_4  \n",
       "4               0     2968356_5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_valid = pd.read_csv(path + \"\\\\data\\\\features_valid.csv\", index_col = 0)\n",
    "dataIDs_valid = pd.read_csv(path + \"\\\\data\\\\dataIDs_valid.csv\", index_col = 0)\n",
    "X_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scale  km_kilometers    m  metres  scale_grp  legend  figure  mapp  \\\n",
       "0      0              0    0       0          0       0       0     0   \n",
       "1      0              0    0       0          0       0       0     0   \n",
       "2      0              0    0       0          0       0       0     0   \n",
       "3      0              0  280       6          1       0       5     0   \n",
       "4      0              1  216       7          1       0       0     0   \n",
       "\n",
       "   alignment_sheet  sheet  figure_grp  north  n  words_in_page  No_of_images  \\\n",
       "0                0      0           0      0  0            424             0   \n",
       "1                0      0           0      0  0             23             0   \n",
       "2                0      0           0      0  0           2243             0   \n",
       "3                0      0           1      0  0           2336             0   \n",
       "4                0      0           0      1  0           1149             0   \n",
       "\n",
       "   Area_of_images  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_features_valid = X_df_valid.copy()\n",
    "X_df_features_valid.drop(columns=['dataID_pageNo'], inplace=True)\n",
    "X_df_features_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555\n",
      "555\n",
      "555\n",
      "555\n"
     ]
    }
   ],
   "source": [
    "Y_df_valid, Y_dfclass_valid = get_Y_values(dataIDs_valid, Pages)\n",
    "\n",
    "print(len(Y_df_valid))\n",
    "print(len(X_df_features_valid))\n",
    "print(len(X_df_valid))\n",
    "print(len(Y_dfclass_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are using regression models as classification models, hence they are collectively reffered to as classification models. <br>\n",
    "\n",
    "First we save the classification models and their names in an array. Then for each of these models first we fit the model using the training dataset and then generate the confusion matrix and accuracy score for each of these models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "name = []\n",
    "# we will create an array of Classifiers and append different classification models to our array.\n",
    "model1 = xgboost.XGBClassifier()\n",
    "classifiers.append(model1)\n",
    "name.append(\"xgboost\")\n",
    "\n",
    "model2 = svm.SVC()\n",
    "classifiers.append(model2)\n",
    "name.append(\"svc\")\n",
    "\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "name.append(\"decisiontree\")\n",
    "\n",
    "model4 = RandomForestClassifier()\n",
    "classifiers.append(model4)\n",
    "name.append(\"rfc\")\n",
    "\n",
    "\n",
    "model5 = RandomForestRegressor(n_estimators=5)\n",
    "classifiers.append(model5)\n",
    "name.append(\"rfr5\")\n",
    "\n",
    "model6 = RandomForestRegressor(n_estimators=25)\n",
    "classifiers.append(model6)\n",
    "name.append(\"rfr25\")\n",
    "\n",
    "model7 = RandomForestRegressor(n_estimators=50)\n",
    "classifiers.append(model7)\n",
    "name.append(\"rfr50\")\n",
    "\n",
    "model8 = RandomForestRegressor(n_estimators=75)\n",
    "classifiers.append(model8)\n",
    "name.append(\"rfr75\")\n",
    "\n",
    "model9 = RandomForestRegressor(n_estimators=100)\n",
    "classifiers.append(model9)\n",
    "name.append(\"rfr100\")\n",
    "\n",
    "\n",
    "model10 = XGBRegressor(n_estimators=5)\n",
    "classifiers.append(model10)\n",
    "name.append(\"xgbr5\")\n",
    "\n",
    "model11 = XGBRegressor(n_estimators=25)\n",
    "classifiers.append(model11)\n",
    "name.append(\"xgbr25\")\n",
    "\n",
    "model12 = XGBRegressor(n_estimators=50)\n",
    "classifiers.append(model12)\n",
    "name.append(\"xgbr50\")\n",
    "\n",
    "model13 = XGBRegressor(n_estimators=75)\n",
    "classifiers.append(model13)\n",
    "name.append(\"xgbr75\")\n",
    "\n",
    "model14 = XGBRegressor(n_estimators=100)\n",
    "classifiers.append(model14)\n",
    "name.append(\"xgbr100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "________________________________________________________\n",
      "[13:44:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgboost\n",
      "Accuracy of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is 1.0\n",
      "Confusion Matrix of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is [[220   0]\n",
      " [  0  29]]\n",
      "________________Validation Set ___________________________\n",
      "xgboost\n",
      "Accuracy of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is 0.9783783783783784\n",
      "Confusion Matrix of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is [[526  12]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "svc\n",
      "Accuracy of SVC() is 0.9397590361445783\n",
      "Confusion Matrix of SVC() is [[220   0]\n",
      " [ 15  14]]\n",
      "________________Validation Set ___________________________\n",
      "svc\n",
      "Accuracy of SVC() is 0.9693693693693693\n",
      "Confusion Matrix of SVC() is [[538   0]\n",
      " [ 17   0]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "decisiontree"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\T1Vibudh\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of DecisionTreeClassifier() is 0.9919678714859438\n",
      "Confusion Matrix of DecisionTreeClassifier() is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "decisiontree\n",
      "Accuracy of DecisionTreeClassifier() is 0.972972972972973\n",
      "Confusion Matrix of DecisionTreeClassifier() is [[523  15]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfc\n",
      "Accuracy of RandomForestClassifier() is 1.0\n",
      "Confusion Matrix of RandomForestClassifier() is [[220   0]\n",
      " [  0  29]]\n",
      "________________Validation Set ___________________________\n",
      "rfc\n",
      "Accuracy of RandomForestClassifier() is 0.9963963963963964\n",
      "Confusion Matrix of RandomForestClassifier() is [[536   2]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr5\n",
      "Accuracy of RandomForestRegressor(n_estimators=5) is 1.0\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=5) is [[220   0]\n",
      " [  0  29]]\n",
      "________________Validation Set ___________________________\n",
      "rfr5\n",
      "Accuracy of RandomForestRegressor(n_estimators=5) is 0.972972972972973\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=5) is [[523  15]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr25\n",
      "Accuracy of RandomForestRegressor(n_estimators=25) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=25) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "rfr25\n",
      "Accuracy of RandomForestRegressor(n_estimators=25) is 0.972972972972973\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=25) is [[523  15]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr50\n",
      "Accuracy of RandomForestRegressor(n_estimators=50) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=50) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "rfr50\n",
      "Accuracy of RandomForestRegressor(n_estimators=50) is 0.972972972972973\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=50) is [[523  15]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr75\n",
      "Accuracy of RandomForestRegressor(n_estimators=75) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=75) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "rfr75\n",
      "Accuracy of RandomForestRegressor(n_estimators=75) is 0.972972972972973\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=75) is [[523  15]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr100\n",
      "Accuracy of RandomForestRegressor() is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor() is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "rfr100\n",
      "Accuracy of RandomForestRegressor() is 0.972972972972973\n",
      "Confusion Matrix of RandomForestRegressor() is [[523  15]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr5\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9919678714859438\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr5\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9693693693693693\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[521  17]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr25\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9919678714859438\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr25\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9693693693693693\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[521  17]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:114: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbr50\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9919678714859438\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr50\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9693693693693693\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[521  17]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr75\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9919678714859438\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr75\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9693693693693693\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[521  17]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr100\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9919678714859438\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   0]\n",
      " [  2  27]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr100\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9693693693693693\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=24, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[521  17]\n",
      " [  0  17]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "cm_test = []\n",
    "cm_valid = []\n",
    "for clf in classifiers:\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"________________________________________________________\")\n",
    "    #fit our algorithms in our Train dataset \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #get test dataset prediction\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_test)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_test)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    test_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    cm_test.append(cm)\n",
    "    \n",
    "    \n",
    "    print(\"________________Validation Set ___________________________\")\n",
    "    #get validation accuracy\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_df_features_valid)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_df_features_valid)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(Y_dfclass_valid[\"Y_class\"], y_pred)\n",
    "    valid_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(Y_dfclass_valid[\"Y_class\"], y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    cm_valid.append(cm)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we save the accuracy score and the confusion matric for the test and validation sets. Then we save the pickled version of the best classification model for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_cm</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_cm</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>svc</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>[[220, 0], [15, 14]]</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>[[538, 0], [17, 0]]</td>\n",
       "      <td>0.910974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>xgbr5</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>[[521, 17], [0, 17]]</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>xgbr25</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>[[521, 17], [0, 17]]</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>xgbr50</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>[[521, 17], [0, 17]]</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>xgbr75</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>[[521, 17], [0, 17]]</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>xgbr100</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>[[521, 17], [0, 17]]</td>\n",
       "      <td>0.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>decisiontree</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>[[523, 15], [0, 17]]</td>\n",
       "      <td>0.965158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>rfr25</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>[[523, 15], [0, 17]]</td>\n",
       "      <td>0.965158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>rfr50</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>[[523, 15], [0, 17]]</td>\n",
       "      <td>0.965158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>rfr75</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>[[523, 15], [0, 17]]</td>\n",
       "      <td>0.965158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>rfr100</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[220, 0], [2, 27]]</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>[[523, 15], [0, 17]]</td>\n",
       "      <td>0.965158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rfr5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[220, 0], [0, 29]]</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>[[523, 15], [0, 17]]</td>\n",
       "      <td>0.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[220, 0], [0, 29]]</td>\n",
       "      <td>0.978378</td>\n",
       "      <td>[[526, 12], [0, 17]]</td>\n",
       "      <td>0.978378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rfc</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[220, 0], [0, 29]]</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>[[536, 2], [0, 17]]</td>\n",
       "      <td>0.996396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  test_accuracy               test_cm  valid_accuracy  \\\n",
       "1            svc       0.939759  [[220, 0], [15, 14]]        0.969369   \n",
       "9          xgbr5       0.991968   [[220, 0], [2, 27]]        0.969369   \n",
       "10        xgbr25       0.991968   [[220, 0], [2, 27]]        0.969369   \n",
       "11        xgbr50       0.991968   [[220, 0], [2, 27]]        0.969369   \n",
       "12        xgbr75       0.991968   [[220, 0], [2, 27]]        0.969369   \n",
       "13       xgbr100       0.991968   [[220, 0], [2, 27]]        0.969369   \n",
       "2   decisiontree       0.991968   [[220, 0], [2, 27]]        0.972973   \n",
       "5          rfr25       0.991968   [[220, 0], [2, 27]]        0.972973   \n",
       "6          rfr50       0.991968   [[220, 0], [2, 27]]        0.972973   \n",
       "7          rfr75       0.991968   [[220, 0], [2, 27]]        0.972973   \n",
       "8         rfr100       0.991968   [[220, 0], [2, 27]]        0.972973   \n",
       "4           rfr5       1.000000   [[220, 0], [0, 29]]        0.972973   \n",
       "0        xgboost       1.000000   [[220, 0], [0, 29]]        0.978378   \n",
       "3            rfc       1.000000   [[220, 0], [0, 29]]        0.996396   \n",
       "\n",
       "                valid_cm   product  \n",
       "1    [[538, 0], [17, 0]]  0.910974  \n",
       "9   [[521, 17], [0, 17]]  0.961583  \n",
       "10  [[521, 17], [0, 17]]  0.961583  \n",
       "11  [[521, 17], [0, 17]]  0.961583  \n",
       "12  [[521, 17], [0, 17]]  0.961583  \n",
       "13  [[521, 17], [0, 17]]  0.961583  \n",
       "2   [[523, 15], [0, 17]]  0.965158  \n",
       "5   [[523, 15], [0, 17]]  0.965158  \n",
       "6   [[523, 15], [0, 17]]  0.965158  \n",
       "7   [[523, 15], [0, 17]]  0.965158  \n",
       "8   [[523, 15], [0, 17]]  0.965158  \n",
       "4   [[523, 15], [0, 17]]  0.972973  \n",
       "0   [[526, 12], [0, 17]]  0.978378  \n",
       "3    [[536, 2], [0, 17]]  0.996396  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_models = pd.DataFrame({'name': name, \n",
    "                                     'test_accuracy': test_accuracy,\n",
    "                                     'test_cm': cm_test, \n",
    "                                     'valid_accuracy':valid_accuracy,\n",
    "                                     'valid_cm': cm_valid})\n",
    "classification_models[\"product\"] = classification_models[\"test_accuracy\"]*classification_models[\"valid_accuracy\"]\n",
    "\n",
    "classification_models = classification_models.sort_values(by=['product'])\n",
    "classification_models.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "\n",
    "for clf in classifiers:\n",
    "    \n",
    "    if name[i] != \"rfc\":\n",
    "        i = i +1\n",
    "        continue\n",
    "    print(name[i])\n",
    "    clf.fit(X_train, y_train)\n",
    "    filename = path + \"\\\\data\\\\alignment_sheet_classifier_rfc.sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    \n",
    "    filename = \"alignment_sheet_classifier_rfr50.sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to observe the features and their importance score for classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>scale</td>\n",
       "      <td>1.084597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>km_kilometers</td>\n",
       "      <td>6.070672e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>1.152203e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>metres</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>scale_grp</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>legend</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>figure</td>\n",
       "      <td>1.440063e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>mapp</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>alignment_sheet</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sheet</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>figure_grp</td>\n",
       "      <td>5.895088e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>north</td>\n",
       "      <td>3.803738e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>words_in_page</td>\n",
       "      <td>1.236311e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No_of_images</td>\n",
       "      <td>4.129831e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Area_of_images</td>\n",
       "      <td>2.293626e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature_Name    Importance\n",
       "0             scale  1.084597e-01\n",
       "1     km_kilometers  6.070672e-02\n",
       "2                 m  1.152203e-02\n",
       "3            metres  0.000000e+00\n",
       "4         scale_grp  0.000000e+00\n",
       "5            legend  0.000000e+00\n",
       "6            figure  1.440063e-05\n",
       "7              mapp  0.000000e+00\n",
       "8   alignment_sheet  0.000000e+00\n",
       "9             sheet  0.000000e+00\n",
       "10       figure_grp  5.895088e-01\n",
       "11            north  3.803738e-07\n",
       "12                n  0.000000e+00\n",
       "13    words_in_page  1.236311e-05\n",
       "14     No_of_images  4.129831e-04\n",
       "15   Area_of_images  2.293626e-01"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_importance = clf.feature_importances_\n",
    "feature = []\n",
    "\n",
    "for col in X_df_features:\n",
    "    feature.append(col)\n",
    "    \n",
    "df_f_importance = pd.DataFrame({'Feature_Name' :  feature, \n",
    "                                'Importance':  f_importance})\n",
    "df_f_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>metres</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>scale_grp</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>legend</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>mapp</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>alignment_sheet</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sheet</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>north</td>\n",
       "      <td>3.803738e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>words_in_page</td>\n",
       "      <td>1.236311e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>figure</td>\n",
       "      <td>1.440063e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No_of_images</td>\n",
       "      <td>4.129831e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>1.152203e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>km_kilometers</td>\n",
       "      <td>6.070672e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>scale</td>\n",
       "      <td>1.084597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Area_of_images</td>\n",
       "      <td>2.293626e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>figure_grp</td>\n",
       "      <td>5.895088e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature_Name    Importance\n",
       "3            metres  0.000000e+00\n",
       "4         scale_grp  0.000000e+00\n",
       "5            legend  0.000000e+00\n",
       "7              mapp  0.000000e+00\n",
       "8   alignment_sheet  0.000000e+00\n",
       "9             sheet  0.000000e+00\n",
       "12                n  0.000000e+00\n",
       "11            north  3.803738e-07\n",
       "13    words_in_page  1.236311e-05\n",
       "6            figure  1.440063e-05\n",
       "14     No_of_images  4.129831e-04\n",
       "2                 m  1.152203e-02\n",
       "1     km_kilometers  6.070672e-02\n",
       "0             scale  1.084597e-01\n",
       "15   Area_of_images  2.293626e-01\n",
       "10       figure_grp  5.895088e-01"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f_importance = df_f_importance.sort_values(by=['Importance'])\n",
    "df_f_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
